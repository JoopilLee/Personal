{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fleanend/TorchGlocalK/blob/main/Glocal_K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl2tU6kL8Ot3",
        "outputId": "379fe638-9ba3-4513-c9d0-6bbd279e03e2"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from scipy.sparse import csc_matrix\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "torch.manual_seed(1284)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4A9uU1WloQ2"
      },
      "source": [
        "# Data Loader Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "p='/home/recordk/reco/BX-Book-Ratings.csv'\n",
        "a=pd.read_csv(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10656.6"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(a[a['Book-Rating']!=0]) *0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100726 65204 35522\n"
          ]
        }
      ],
      "source": [
        "print(len(a),len(a[a['Book-Rating']==0]),len(a[a['Book-Rating']!=0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "test=a[a['Book-Rating']!=0]\n",
        "test_x=test.drop('Book-Rating',axis=1)\n",
        "test_y=test['Book-Rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "le2=LabelEncoder()\n",
        "test_x['ISBN']=le.fit_transform(test_x['ISBN'])\n",
        "test_x['User-ID']=le2.fit_transform(test_x['User-ID'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test=train_test_split(test_x,test_y,test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "tr=pd.concat([x_train,y_train],axis=1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tr=pd.concat([x_train,y_train],axis=1).values\n",
        "# tr=pd.concat([tr,a[a['Book-Rating']==0]]).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 4745, 16706,     5],\n",
              "       [ 4242, 18315,     7],\n",
              "       [ 2542,  6440,    10],\n",
              "       ...,\n",
              "       [ 1002, 18946,     8],\n",
              "       [ 1956, 17899,     5],\n",
              "       [  635, 13057,     6]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "te=pd.concat([x_test,y_test],axis=1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   98,  9542,     8],\n",
              "       [ 1940,  3865,     9],\n",
              "       [ 3996,  4924,     8],\n",
              "       ...,\n",
              "       [  858, 15141,     9],\n",
              "       [ 3935,  2082,     9],\n",
              "       [ 3371,    44,    10]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([276762, 276762, 276762, ..., 276579, 276579, 276579], dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.values[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cq3KEUaVo1o3"
      },
      "outputs": [],
      "source": [
        "def load_data_100k(path='./data/', delimiter='\\t'):\n",
        "\n",
        "    # train = np.loadtxt(path+'movielens_100k_u1.base', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    # test = np.loadtxt(path+'movielens_100k_u1.test', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    train =tr\n",
        "    test=te\n",
        "    total = np.concatenate((train, test), axis=0)\n",
        "    print(train)\n",
        "    print(test)\n",
        "    print(total)\n",
        "    n_u = np.unique(total[:,0]).size  # num of users\n",
        "    n_m = np.unique(total[:,1]).size  # num of movies\n",
        "    n_train = train.shape[0]  # num of training ratings\n",
        "    n_test = test.shape[0]  # num of test ratings\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_train):\n",
        "        train_r[train[i,1]-1, train[i,0]-1] = train[i,2]\n",
        "\n",
        "    for i in range(n_test):\n",
        "        test_r[test[i,1]-1, test[i,0]-1] = test[i,2]\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8kEkg9mlIW"
      },
      "source": [
        "# Load Data ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0fkA1WpmipzF"
      },
      "outputs": [],
      "source": [
        "# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "data_path = ''\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJqSSY33mgkw",
        "outputId": "54f7ca43-b9f7-4edb-8628-783a4513f4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 4745 16706     5]\n",
            " [ 4242 18315     7]\n",
            " [ 2542  6440    10]\n",
            " ...\n",
            " [ 1002 18946     8]\n",
            " [ 1956 17899     5]\n",
            " [  635 13057     6]]\n",
            "[[   98  9542     8]\n",
            " [ 1940  3865     9]\n",
            " [ 3996  4924     8]\n",
            " ...\n",
            " [  858 15141     9]\n",
            " [ 3935  2082     9]\n",
            " [ 3371    44    10]]\n",
            "[[ 4745 16706     5]\n",
            " [ 4242 18315     7]\n",
            " [ 2542  6440    10]\n",
            " ...\n",
            " [  858 15141     9]\n",
            " [ 3935  2082     9]\n",
            " [ 3371    44    10]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data matrix loaded\n",
            "num of users: 4777\n",
            "num of movies: 22222\n",
            "num of training ratings: 24865\n",
            "num of test ratings: 10657\n"
          ]
        }
      ],
      "source": [
        "# Data Load\n",
        "try:\n",
        "    path = data_path + '/content/Glocal_K/data/MovieLens_100K/'\n",
        "    n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(delimiter='\\t')\n",
        "except Exception:\n",
        "    print('Error: Unable to load data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 4745 16706     5]\n",
            " [ 4242 18315     7]\n",
            " [ 2542  6440    10]\n",
            " ...\n",
            " [ 1002 18946     8]\n",
            " [ 1956 17899     5]\n",
            " [  635 13057     6]]\n",
            "[[   98  9542     8]\n",
            " [ 1940  3865     9]\n",
            " [ 3996  4924     8]\n",
            " ...\n",
            " [  858 15141     9]\n",
            " [ 3935  2082     9]\n",
            " [ 3371    44    10]]\n",
            "[[ 4745 16706     5]\n",
            " [ 4242 18315     7]\n",
            " [ 2542  6440    10]\n",
            " ...\n",
            " [  858 15141     9]\n",
            " [ 3935  2082     9]\n",
            " [ 3371    44    10]]\n",
            "data matrix loaded\n",
            "num of users: 4777\n",
            "num of movies: 22222\n",
            "num of training ratings: 24865\n",
            "num of test ratings: 10657\n"
          ]
        }
      ],
      "source": [
        "n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nGCdp_FlobOK"
      },
      "outputs": [],
      "source": [
        "# Common hyperparameter settings\n",
        "n_hid = 500 # size of hidden layers\n",
        "n_dim = 5 # inner AE embedding size\n",
        "n_layers = 2 # number of hidden layers\n",
        "gk_size = 3 # width=height of kernel for convolution\n",
        "    \n",
        "# Hyperparameters to tune for specific case\n",
        "max_epoch_p = 500 # max number of epochs for pretraining\n",
        "max_epoch_f = 1000 # max number of epochs for finetuning\n",
        "patience_p = 5 # number of consecutive rounds of early stopping condition before actual stop for pretraining\n",
        "patience_f = 10 # and finetuning\n",
        "tol_p = 1e-4 # minimum threshold for the difference between consecutive values of train rmse, used for early stopping, for pretraining\n",
        "tol_f = 1e-5 # and finetuning\n",
        "lambda_2 = 20. # regularisation of number or parameters\n",
        "lambda_s = 0.006 # regularisation of sparsity of the final matrix\n",
        "dot_scale = 1 # dot product weight for global kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sWtU4-pmDDT"
      },
      "source": [
        "# Network Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p1P6fgYiy28F"
      },
      "outputs": [],
      "source": [
        "def local_kernel(u, v):\n",
        "    dist = torch.norm(u - v, p=2, dim=2)\n",
        "    hat = torch.clamp(1. - dist**2, min=0.)\n",
        "    return hat\n",
        "\n",
        "class KernelLayer(nn.Module):\n",
        "    def __init__(self, n_in, n_hid, n_dim, lambda_s, lambda_2, activation=nn.Sigmoid()):\n",
        "      super().__init__()\n",
        "      self.W = nn.Parameter(torch.randn(n_in, n_hid))\n",
        "      self.u = nn.Parameter(torch.randn(n_in, 1, n_dim))\n",
        "      self.v = nn.Parameter(torch.randn(1, n_hid, n_dim))\n",
        "      self.b = nn.Parameter(torch.randn(n_hid))\n",
        "\n",
        "      self.lambda_s = lambda_s\n",
        "      self.lambda_2 = lambda_2\n",
        "\n",
        "      nn.init.xavier_uniform_(self.W, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
        "      nn.init.xavier_uniform_(self.u, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
        "      nn.init.xavier_uniform_(self.v, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
        "      nn.init.zeros_(self.b)\n",
        "      self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "      w_hat = local_kernel(self.u, self.v)\n",
        "    \n",
        "      sparse_reg = torch.nn.functional.mse_loss(w_hat, torch.zeros_like(w_hat))\n",
        "      sparse_reg_term = self.lambda_s * sparse_reg\n",
        "      \n",
        "      l2_reg = torch.nn.functional.mse_loss(self.W, torch.zeros_like(self.W))\n",
        "      l2_reg_term = self.lambda_2 * l2_reg\n",
        "\n",
        "      W_eff = self.W * w_hat  # Local kernelised weight matrix\n",
        "      y = torch.matmul(x, W_eff) + self.b\n",
        "      y = self.activation(y)\n",
        "\n",
        "      return y, sparse_reg_term + l2_reg_term\n",
        "\n",
        "class KernelNet(nn.Module):\n",
        "    def __init__(self, n_u, n_hid, n_dim, n_layers, lambda_s, lambda_2):\n",
        "      super().__init__()\n",
        "      layers = []\n",
        "      for i in range(n_layers):\n",
        "        if i == 0:\n",
        "          layers.append(KernelLayer(n_u, n_hid, n_dim, lambda_s, lambda_2))\n",
        "        else:\n",
        "          layers.append(KernelLayer(n_hid, n_hid, n_dim, lambda_s, lambda_2))\n",
        "      layers.append(KernelLayer(n_hid, n_u, n_dim, lambda_s, lambda_2, activation=nn.Identity()))\n",
        "      self.layers = nn.ModuleList(layers)\n",
        "      self.dropout = nn.Dropout(0.33)\n",
        "\n",
        "    def forward(self, x):\n",
        "      total_reg = None\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        x, reg = layer(x)\n",
        "        if i < len(self.layers)-1:\n",
        "          x = self.dropout(x)\n",
        "        if total_reg is None:\n",
        "          total_reg = reg\n",
        "        else:\n",
        "          total_reg += reg\n",
        "      return x, total_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7RGKh1ckXgtP"
      },
      "outputs": [],
      "source": [
        "class CompleteNet(nn.Module):\n",
        "    def __init__(self, kernel_net, n_u, n_m, n_hid, n_dim, n_layers, lambda_s, lambda_2, gk_size, dot_scale):\n",
        "      super().__init__()\n",
        "      self.gk_size = gk_size\n",
        "      self.dot_scale = dot_scale\n",
        "      self.local_kernel_net = kernel_net\n",
        "      # self.local_kernel_net = nn.ModuleList([kernel_net])\n",
        "\n",
        "      self.conv_kernel = torch.nn.Parameter(torch.randn(n_m, gk_size**2) * 0.1)\n",
        "      nn.init.xavier_uniform_(self.conv_kernel, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
        "      \n",
        "\n",
        "    def forward(self, x, x_local):\n",
        "      gk = self.global_kernel(x_local, self.gk_size, self.dot_scale)\n",
        "      x = self.global_conv(x, gk)\n",
        "      x, global_reg_loss = self.local_kernel_net(x)\n",
        "      return x, global_reg_loss\n",
        "\n",
        "    def global_kernel(self, input, gk_size, dot_scale):\n",
        "      avg_pooling = torch.mean(input, dim=1)  # Item (axis=1) based average pooling\n",
        "      avg_pooling = avg_pooling.view(1, -1)\n",
        "      # print('#'*10,avg_pooling.shape, self.conv_kernel.shape)\n",
        "      gk = torch.matmul(avg_pooling, self.conv_kernel) * dot_scale  # Scaled dot product\n",
        "      gk = gk.view(1, 1, gk_size, gk_size)\n",
        "\n",
        "      return gk\n",
        "\n",
        "    def global_conv(self, input, W):\n",
        "      input = input.unsqueeze(0).unsqueeze(0)\n",
        "      conv2d = nn.LeakyReLU()(F.conv2d(input, W, stride=1, padding=1))\n",
        "      return conv2d.squeeze(0).squeeze(0)\n",
        "\n",
        "class Loss(nn.Module):\n",
        "    def forward(self, pred_p, reg_loss, train_m, train_r):\n",
        "      # L2 loss\n",
        "      diff = train_m * (train_r - pred_p)\n",
        "      sqE = torch.nn.functional.mse_loss(diff, torch.zeros_like(diff))\n",
        "      loss_p = sqE + reg_loss\n",
        "      return loss_p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sQCwrSmKG4"
      },
      "source": [
        "# Network Instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtWj1SCo1RW"
      },
      "source": [
        "## Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[f'cuda:{i}' for i in [0,1,2,3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7teUrgWagpW0"
      },
      "outputs": [],
      "source": [
        "device =torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = KernelNet(n_u, n_hid, n_dim, n_layers, lambda_s, lambda_2).double().to(device)\n",
        "# Check if multiple GPUs are available\n",
        "# if torch.cuda.device_count() > 1:\n",
        "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "#     model = nn.DataParallel(model,device_ids=[0,1,2,3])\n",
        "\n",
        "# Move the model to GPU\n",
        "# model = model.to(device)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IEBsNhNo4Cj"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OiTXqnN6zLXQ"
      },
      "outputs": [],
      "source": [
        "complete_model = CompleteNet(model, n_u, n_m, n_hid, n_dim, n_layers, lambda_s, lambda_2, gk_size, dot_scale).double().to(device)\n",
        "\n",
        "# if torch.cuda.device_count() > 1:\n",
        "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "#     complete_model = nn.DataParallel(complete_model,device_ids=[0,1,2,3])\n",
        "\n",
        "# Move the model to GPU\n",
        "complete_model = complete_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=1)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETwz58aK6y6"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vyReXxgac3KH"
      },
      "outputs": [],
      "source": [
        "def dcg_k(score_label, k):\n",
        "    dcg, i = 0., 0\n",
        "    for s in score_label:\n",
        "        if i < k:\n",
        "            dcg += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    return dcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jwsSR-8ZdGWo"
      },
      "outputs": [],
      "source": [
        "def ndcg_k(y_hat, y, k):\n",
        "    score_label = np.stack([y_hat, y], axis=1).tolist()\n",
        "    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n",
        "    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n",
        "    norm, i = 0., 0\n",
        "    for s in score_label_:\n",
        "        if i < k:\n",
        "            norm += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    dcg = dcg_k(score_label, k)\n",
        "    return dcg / norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yy9eQS51pbhj"
      },
      "outputs": [],
      "source": [
        "def call_ndcg(y_hat, y):\n",
        "    ndcg_sum, num = 0, 0\n",
        "    y_hat, y = y_hat.T, y.T\n",
        "    n_users = y.shape[0]\n",
        "\n",
        "    for i in range(n_users):\n",
        "        y_hat_i = y_hat[i][np.where(y[i])]\n",
        "        y_i = y[i][np.where(y[i])]\n",
        "\n",
        "        if y_i.shape[0] < 2:\n",
        "            continue\n",
        "\n",
        "        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n",
        "        num += 1\n",
        "\n",
        "    return ndcg_sum / num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXQjeMxmYEC"
      },
      "source": [
        "# Training and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ35Zoha-Eue",
        "outputId": "4fc0c647-b0a5-4e69-afff-899c14dc247d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 0 test rmse: 6.986413 train rmse: 6.9819584\n",
            "Time: 1.1739418506622314 seconds\n",
            "Time cumulative: 1.1739418506622314 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 50 test rmse: 4.2616973 train rmse: 3.939104\n",
            "Time: 137.5244755744934 seconds\n",
            "Time cumulative: 3537.6545436382294 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 75 test rmse: 4.1802683 train rmse: 3.8537848\n",
            "Time: 202.9475908279419 seconds\n",
            "Time cumulative: 7655.298001527786 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n"
          ]
        }
      ],
      "source": [
        "best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\n",
        "best_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n",
        "\n",
        "time_cumulative = 0\n",
        "tic = time()\n",
        "\n",
        "# Pre-Training\n",
        "optimizer = torch.optim.AdamW(complete_model.local_kernel_net.parameters(), lr=0.001)\n",
        "# optimizer = torch.optim.AdamW(complete_model.module.local_kernel_net.parameters(), lr=0.001)\n",
        "\n",
        "def closure():\n",
        "  optimizer.zero_grad()\n",
        "  x = torch.Tensor(train_r).double().to(device)\n",
        "  m = torch.Tensor(train_m).double().to(device)\n",
        "  \n",
        "  complete_model.local_kernel_net.train()\n",
        "  # complete_model.module.local_kernel_net.train()\n",
        "  \n",
        "  pred, reg = complete_model.local_kernel_net(x)\n",
        "  # pred, reg = complete_model.module.local_kernel_net(x)\n",
        "  loss = Loss().to(device)(pred, reg, m, x)\n",
        "  loss.backward()\n",
        "  return loss\n",
        "\n",
        "last_rmse = np.inf\n",
        "counter = 0\n",
        "\n",
        "for i in range(max_epoch_p):\n",
        "  optimizer.step(closure)\n",
        "  \n",
        "  complete_model.local_kernel_net.eval()\n",
        "  # complete_model.module.local_kernel_net.eval()\n",
        "  t = time() - tic\n",
        "  time_cumulative += t\n",
        "\n",
        "  pre, _ = model(torch.Tensor(train_r).double().to(device))\n",
        "  \n",
        "  pre = pre.float().cpu().detach().numpy()\n",
        "  \n",
        "  error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "  test_rmse = np.sqrt(error)\n",
        "\n",
        "  error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "  train_rmse = np.sqrt(error_train)\n",
        "\n",
        "  if last_rmse-train_rmse < tol_p:\n",
        "    counter += 1\n",
        "  else:\n",
        "    counter = 0\n",
        "\n",
        "  last_rmse = train_rmse\n",
        "\n",
        "  if patience_p == counter:\n",
        "    print('.-^-._' * 12)\n",
        "    print('PRE-TRAINING')\n",
        "    print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n",
        "    print('Time:', t, 'seconds')\n",
        "    print('Time cumulative:', time_cumulative, 'seconds')\n",
        "    print('.-^-._' * 12)\n",
        "    break\n",
        "\n",
        "\n",
        "  if i % 50 != 0:\n",
        "    continue\n",
        "  print('.-^-._' * 12)\n",
        "  print('PRE-TRAINING')\n",
        "  print('Epoch:', i, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n",
        "  print('Time:', t, 'seconds')\n",
        "  print('Time cumulative:', time_cumulative, 'seconds')\n",
        "  print('.-^-._' * 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6v_tODcweLn",
        "outputId": "5ab3f058-5c7c-458a-c3b5-32bbcf4df418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 0 test rmse: 4.018015 test mae: 3.564016 test ndcg: 0.8734342013268793\n",
            "Epoch: 0 train rmse: 3.6753216 train mae: 3.2868927 train ndcg: 0.8545042217177146\n",
            "Time: 208.5083131790161 seconds\n",
            "Time cumulative: 7863.806314706802 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            "########## torch.Size([1, 22222]) torch.Size([22222, 9])\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 17 test rmse: 4.042038 test mae: 3.5930681 test ndcg: 0.8725079992357471\n",
            "Epoch: 17 train rmse: 3.701089 train mae: 3.3184028 train ndcg: 0.8546721931624013\n",
            "Time: 358.66336822509766 seconds\n",
            "Time cumulative: 12469.781433105469 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n"
          ]
        }
      ],
      "source": [
        "# Fine-Tuning\n",
        "\n",
        "train_r_local = np.clip(pre, 1., 5.)\n",
        "\n",
        "optimizer = torch.optim.AdamW(complete_model.parameters(), lr=0.001)\n",
        "# complete_model=nn.DataParallel(complete_model)\n",
        "def closure():\n",
        "  optimizer.zero_grad()\n",
        "  x = torch.Tensor(train_r).double().to(device)\n",
        "  x_local = torch.Tensor(train_r_local).double().to(device)\n",
        "  m = torch.Tensor(train_m).double().to(device)\n",
        "  complete_model.train()\n",
        "  pred, reg = complete_model(x, x_local)\n",
        "  loss = Loss().to(device)(pred, reg, m, x)\n",
        "  loss.backward()\n",
        "  return loss\n",
        "\n",
        "last_rmse = np.inf\n",
        "counter = 0\n",
        "\n",
        "for i in range(max_epoch_f):\n",
        "  optimizer.step(closure)\n",
        "  complete_model.eval()\n",
        "  t = time() - tic\n",
        "  time_cumulative += t\n",
        "\n",
        "  pre, _ = complete_model(torch.Tensor(train_r).double().to(device), torch.Tensor(train_r_local).double().to(device))\n",
        "  \n",
        "  pre = pre.float().cpu().detach().numpy()\n",
        "\n",
        "  error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "  test_rmse = np.sqrt(error)\n",
        "\n",
        "  error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "  train_rmse = np.sqrt(error_train)\n",
        "\n",
        "  test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n",
        "  train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n",
        "\n",
        "  test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n",
        "  train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n",
        "\n",
        "  if test_rmse < best_rmse:\n",
        "      best_rmse = test_rmse\n",
        "      best_rmse_ep = i+1\n",
        "\n",
        "  if test_mae < best_mae:\n",
        "      best_mae = test_mae\n",
        "      best_mae_ep = i+1\n",
        "\n",
        "  if best_ndcg < test_ndcg:\n",
        "      best_ndcg = test_ndcg\n",
        "      best_ndcg_ep = i+1\n",
        "\n",
        "  if last_rmse-train_rmse < tol_f:\n",
        "    counter += 1\n",
        "  else:\n",
        "    counter = 0\n",
        "\n",
        "  last_rmse = train_rmse\n",
        "\n",
        "  if patience_f == counter:\n",
        "    print('.-^-._' * 12)\n",
        "    print('FINE-TUNING')\n",
        "    print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n",
        "    print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n",
        "    print('Time:', t, 'seconds')\n",
        "    print('Time cumulative:', time_cumulative, 'seconds')\n",
        "    print('.-^-._' * 12)\n",
        "    break\n",
        "\n",
        "\n",
        "  if i % 50 != 0:\n",
        "    continue\n",
        "\n",
        "  print('.-^-._' * 12)\n",
        "  print('FINE-TUNING')\n",
        "  print('Epoch:', i, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n",
        "  print('Epoch:', i, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n",
        "  print('Time:', t, 'seconds')\n",
        "  print('Time cumulative:', time_cumulative, 'seconds')\n",
        "  print('.-^-._' * 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTi_PdXJqTjh",
        "outputId": "6f5a2d63-2c1f-446f-8f20-d4357d4bdc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7  best rmse: 3.988716\n",
            "Epoch: 7  best mae: 3.543069\n",
            "Epoch: 1  best ndcg: 0.8734342013268793\n"
          ]
        }
      ],
      "source": [
        "# Final result\n",
        "print('Epoch:', best_rmse_ep, ' best rmse:', best_rmse)\n",
        "print('Epoch:', best_mae_ep, ' best mae:', best_mae)\n",
        "print('Epoch:', best_ndcg_ep, ' best ndcg:', best_ndcg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([34])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.transform(['013022393X'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "book=pd.read_csv('/home/recordk/reco/BX-Books.csv',encoding='CP949')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ISBN</th>\n",
              "      <th>Book-Title</th>\n",
              "      <th>Book-Author</th>\n",
              "      <th>Year-Of-Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Image-URL-S</th>\n",
              "      <th>Image-URL-M</th>\n",
              "      <th>Image-URL-L</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9643112136</td>\n",
              "      <td>Dalan-i bihisht (Dastan-i Irani)</td>\n",
              "      <td>Nazi Safavi</td>\n",
              "      <td>1378</td>\n",
              "      <td>Intisharat-i Quqnus</td>\n",
              "      <td>http://images.amazon.com/images/P/9643112136.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/9643112136.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/9643112136.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1551103982</td>\n",
              "      <td>The Cycling Adventures of Coconut Head: A Nort...</td>\n",
              "      <td>Ted Schredd</td>\n",
              "      <td>1900</td>\n",
              "      <td>Graphic Arts Center Pub Co</td>\n",
              "      <td>http://images.amazon.com/images/P/1551103982.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/1551103982.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/1551103982.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>013022393X</td>\n",
              "      <td>All the Best Salads and Salad Dressings</td>\n",
              "      <td>J. Warner</td>\n",
              "      <td>1911</td>\n",
              "      <td>Prentice Hall Direct</td>\n",
              "      <td>http://images.amazon.com/images/P/013022393X.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/013022393X.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/013022393X.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>030758013X</td>\n",
              "      <td>Assorted Small Tray Puzzles</td>\n",
              "      <td>Golden</td>\n",
              "      <td>1920</td>\n",
              "      <td>Golden Books</td>\n",
              "      <td>http://images.amazon.com/images/P/030758013X.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/030758013X.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/030758013X.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>082493069X</td>\n",
              "      <td>Grill and Barbecue Cooking</td>\n",
              "      <td>Ideals Publications Inc</td>\n",
              "      <td>1920</td>\n",
              "      <td>Ideals Publications</td>\n",
              "      <td>http://images.amazon.com/images/P/082493069X.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/082493069X.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/082493069X.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44360</th>\n",
              "      <td>B00007MF56</td>\n",
              "      <td>More, Now, Again: A Memoir of Addiction</td>\n",
              "      <td>Elizabeth Wurtzel</td>\n",
              "      <td>2001</td>\n",
              "      <td>Simon &amp;amp Schuster</td>\n",
              "      <td>http://images.amazon.com/images/P/B00007MF56.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00007MF56.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00007MF56.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44361</th>\n",
              "      <td>B00007CWGV</td>\n",
              "      <td>Madonna</td>\n",
              "      <td>Andrew Morton</td>\n",
              "      <td>2001</td>\n",
              "      <td>St. Martin's Press</td>\n",
              "      <td>http://images.amazon.com/images/P/B00007CWGV.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00007CWGV.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00007CWGV.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44362</th>\n",
              "      <td>B000078UH8</td>\n",
              "      <td>The Hearing</td>\n",
              "      <td>John T. Lescroart</td>\n",
              "      <td>2001</td>\n",
              "      <td>E P Dutton</td>\n",
              "      <td>http://images.amazon.com/images/P/B000078UH8.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B000078UH8.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B000078UH8.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44363</th>\n",
              "      <td>B00006JO6O</td>\n",
              "      <td>The Last Precinct</td>\n",
              "      <td>Patricia Daniels Cornwell</td>\n",
              "      <td>2000</td>\n",
              "      <td>Putnam Pub Group</td>\n",
              "      <td>http://images.amazon.com/images/P/B00006JO6O.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00006JO6O.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00006JO6O.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44364</th>\n",
              "      <td>B00008RWPV</td>\n",
              "      <td>McNally's Chance</td>\n",
              "      <td>Lawrence Sanders</td>\n",
              "      <td>2001</td>\n",
              "      <td>Putnam Pub Group</td>\n",
              "      <td>http://images.amazon.com/images/P/B00008RWPV.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00008RWPV.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/B00008RWPV.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44365 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ISBN                                         Book-Title  \\\n",
              "0      9643112136                   Dalan-i bihisht (Dastan-i Irani)   \n",
              "1      1551103982  The Cycling Adventures of Coconut Head: A Nort...   \n",
              "2      013022393X            All the Best Salads and Salad Dressings   \n",
              "3      030758013X                        Assorted Small Tray Puzzles   \n",
              "4      082493069X                         Grill and Barbecue Cooking   \n",
              "...           ...                                                ...   \n",
              "44360  B00007MF56            More, Now, Again: A Memoir of Addiction   \n",
              "44361  B00007CWGV                                            Madonna   \n",
              "44362  B000078UH8                                        The Hearing   \n",
              "44363  B00006JO6O                                  The Last Precinct   \n",
              "44364  B00008RWPV                                   McNally's Chance   \n",
              "\n",
              "                     Book-Author  Year-Of-Publication  \\\n",
              "0                    Nazi Safavi                 1378   \n",
              "1                    Ted Schredd                 1900   \n",
              "2                      J. Warner                 1911   \n",
              "3                         Golden                 1920   \n",
              "4        Ideals Publications Inc                 1920   \n",
              "...                          ...                  ...   \n",
              "44360          Elizabeth Wurtzel                 2001   \n",
              "44361              Andrew Morton                 2001   \n",
              "44362          John T. Lescroart                 2001   \n",
              "44363  Patricia Daniels Cornwell                 2000   \n",
              "44364           Lawrence Sanders                 2001   \n",
              "\n",
              "                        Publisher  \\\n",
              "0             Intisharat-i Quqnus   \n",
              "1      Graphic Arts Center Pub Co   \n",
              "2            Prentice Hall Direct   \n",
              "3                    Golden Books   \n",
              "4             Ideals Publications   \n",
              "...                           ...   \n",
              "44360         Simon &amp Schuster   \n",
              "44361          St. Martin's Press   \n",
              "44362                  E P Dutton   \n",
              "44363            Putnam Pub Group   \n",
              "44364            Putnam Pub Group   \n",
              "\n",
              "                                             Image-URL-S  \\\n",
              "0      http://images.amazon.com/images/P/9643112136.0...   \n",
              "1      http://images.amazon.com/images/P/1551103982.0...   \n",
              "2      http://images.amazon.com/images/P/013022393X.0...   \n",
              "3      http://images.amazon.com/images/P/030758013X.0...   \n",
              "4      http://images.amazon.com/images/P/082493069X.0...   \n",
              "...                                                  ...   \n",
              "44360  http://images.amazon.com/images/P/B00007MF56.0...   \n",
              "44361  http://images.amazon.com/images/P/B00007CWGV.0...   \n",
              "44362  http://images.amazon.com/images/P/B000078UH8.0...   \n",
              "44363  http://images.amazon.com/images/P/B00006JO6O.0...   \n",
              "44364  http://images.amazon.com/images/P/B00008RWPV.0...   \n",
              "\n",
              "                                             Image-URL-M  \\\n",
              "0      http://images.amazon.com/images/P/9643112136.0...   \n",
              "1      http://images.amazon.com/images/P/1551103982.0...   \n",
              "2      http://images.amazon.com/images/P/013022393X.0...   \n",
              "3      http://images.amazon.com/images/P/030758013X.0...   \n",
              "4      http://images.amazon.com/images/P/082493069X.0...   \n",
              "...                                                  ...   \n",
              "44360  http://images.amazon.com/images/P/B00007MF56.0...   \n",
              "44361  http://images.amazon.com/images/P/B00007CWGV.0...   \n",
              "44362  http://images.amazon.com/images/P/B000078UH8.0...   \n",
              "44363  http://images.amazon.com/images/P/B00006JO6O.0...   \n",
              "44364  http://images.amazon.com/images/P/B00008RWPV.0...   \n",
              "\n",
              "                                             Image-URL-L  \n",
              "0      http://images.amazon.com/images/P/9643112136.0...  \n",
              "1      http://images.amazon.com/images/P/1551103982.0...  \n",
              "2      http://images.amazon.com/images/P/013022393X.0...  \n",
              "3      http://images.amazon.com/images/P/030758013X.0...  \n",
              "4      http://images.amazon.com/images/P/082493069X.0...  \n",
              "...                                                  ...  \n",
              "44360  http://images.amazon.com/images/P/B00007MF56.0...  \n",
              "44361  http://images.amazon.com/images/P/B00007CWGV.0...  \n",
              "44362  http://images.amazon.com/images/P/B000078UH8.0...  \n",
              "44363  http://images.amazon.com/images/P/B00006JO6O.0...  \n",
              "44364  http://images.amazon.com/images/P/B00008RWPV.0...  \n",
              "\n",
              "[44365 rows x 8 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index([100722, 100724], dtype='int64')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user=276579\n",
        "a[(a['User-ID']==user)&(a['Book-Rating']>0)].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User-ID</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>Book-Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>276762</td>\n",
              "      <td>3404122879</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>276762</td>\n",
              "      <td>3404182928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>276762</td>\n",
              "      <td>3426690179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>276762</td>\n",
              "      <td>3442424216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>276762</td>\n",
              "      <td>3442425573</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100719</th>\n",
              "      <td>267609</td>\n",
              "      <td>3785715382</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100720</th>\n",
              "      <td>267609</td>\n",
              "      <td>3785715390</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100721</th>\n",
              "      <td>267609</td>\n",
              "      <td>3785721080</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100723</th>\n",
              "      <td>276579</td>\n",
              "      <td>087579159X</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100725</th>\n",
              "      <td>276579</td>\n",
              "      <td>1577591062</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100724 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        User-ID        ISBN  Book-Rating\n",
              "0        276762  3404122879            0\n",
              "1        276762  3404182928            0\n",
              "2        276762  3426690179            0\n",
              "3        276762  3442424216            0\n",
              "4        276762  3442425573            0\n",
              "...         ...         ...          ...\n",
              "100719   267609  3785715382            0\n",
              "100720   267609  3785715390            0\n",
              "100721   267609  3785721080            0\n",
              "100723   276579  087579159X            0\n",
              "100725   276579  1577591062            0\n",
              "\n",
              "[100724 rows x 3 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.drop(a[(a['User-ID']==user)&(a['Book-Rating']>0)].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "le.transform([user])\n",
        "le2.transform()\n",
        "complete_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>4767</th>\n",
              "      <th>4768</th>\n",
              "      <th>4769</th>\n",
              "      <th>4770</th>\n",
              "      <th>4771</th>\n",
              "      <th>4772</th>\n",
              "      <th>4773</th>\n",
              "      <th>4774</th>\n",
              "      <th>4775</th>\n",
              "      <th>4776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22217</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22218</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22219</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22220</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22221</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22222 rows × 4777 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     2     3     4     5     6     7     8     9     ...  4767  \\\n",
              "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "22217   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "22218   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "22219   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "22220   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "22221   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "\n",
              "       4768  4769  4770  4771  4772  4773  4774  4775  4776  \n",
              "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "22217   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "22218   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "22219   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "22220   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "22221   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[22222 rows x 4777 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(train_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 추천하기\n",
        "def recommender(user, n_items=10):\n",
        "    # 현재 사용자의 모든 아이템에 대한 예상 평점 계산\n",
        "    predictions = []\n",
        "    # rated_index = a[a['Book-Rating']>0].index    # 이미 평가한 책 확인\n",
        "    rated_index = a[(a['User-ID']==user)&(a['Book-Rating']>0)].index\n",
        "    # items = a.loc[user].drop(rated_index)\n",
        "    books = a.drop(rated_index)\n",
        "    for book in books.index:\n",
        "        # predictions.append(complete_model.get_one_prediction(le.transform([user]), le2.transform([book])))                   # 예상평점 계산\n",
        "        predictions.append(complete_model(le.transform([user]), le2.transform([book])))                   # 예상평점 계산\n",
        "    recommendations = pd.Series(data=predictions, index=books.index, dtype=float)\n",
        "    recommendations = recommendations.sort_values(ascending=False)[:n_items]    # 예상평점이 가장 높은 영화 선택\n",
        "    recommended_items = book.loc[recommendations.index]['title']\n",
        "    return recommended_items"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
